{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadData(filePath):\n",
    "    dataframe= pandas.read_csv(filePath)\n",
    "    del dataframe['Name']\n",
    "    del dataframe['Cabin']\n",
    "    del dataframe['Fare']\n",
    "    del dataframe['Ticket']\n",
    "    del dataframe['SibSp']\n",
    "    del dataframe['PassengerId']\n",
    "    del dataframe['Embarked']\n",
    "    del dataframe['Parch']\n",
    "    return dataframe\n",
    "train = loadData('./Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age\n",
       "0         0       3    male  22.0\n",
       "1         1       1  female  38.0\n",
       "2         1       3  female  26.0\n",
       "3         1       1  female  35.0\n",
       "4         0       3    male  35.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Train Data\"\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 3)\n",
      "(891, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split-out validation dataset\n",
    "\n",
    "train =train.replace({'male':1,'female':0})\n",
    "\n",
    "#Replacing the NaN with zeros\n",
    "train.fillna(0, inplace=True)\n",
    "\n",
    "array = train.values\n",
    "#Extracting the data features\n",
    "X = array[:,1:4]\n",
    "\n",
    "print X.shape\n",
    "#Creating label array\n",
    "Y = array[:,0:1]\n",
    "print Y.shape\n",
    "\n",
    "#Splitting the dataset into train and validation sets\n",
    "validation_size = 0.20\n",
    "seed = 21\n",
    "X_train, X_validation, Y_train, Y_validation = cross_validation.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = Logistic Regression:\n",
      " mean = 0.786502 std = (0.041145)\n",
      "\n",
      "model = Linear Discriminant Analysis:\n",
      " mean = 0.786502 std = (0.041145)\n",
      "\n",
      "model = KNN:\n",
      " mean = 0.752778 std = (0.044019)\n",
      "\n",
      "model = CART Decision Tree:\n",
      " mean = 0.807551 std = (0.039377)\n",
      "\n",
      "model = Naive Bayes:\n",
      " mean = 0.787911 std = (0.039476)\n",
      "\n",
      "model = SVM:\n",
      " mean = 0.780810 std = (0.036158)\n",
      "\n",
      "[ 1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  1.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.\n",
      "  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  0.  0.  1.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.  0.\n",
      "  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Test options and evaluation metric\n",
    "num_folds = 10\n",
    "num_instances = len(X_train)\n",
    "seed = 3\n",
    "\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Linear Discriminant Analysis', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART Decision Tree', DecisionTreeClassifier()))\n",
    "models.append(('Naive Bayes', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed)\n",
    "    cv_results = cross_validation.cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"model = %s:\\n mean = %f std = (%f)\\n\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Using Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required headers and initializing the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/usr/local/spark\")\n",
    "import pyspark  \n",
    "from pyspark import SparkContext\n",
    "sc =SparkContext()\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import NaiveBayes,NaiveBayesModel\n",
    "import pyspark.mllib.regression as mllib_reg\n",
    "import pyspark.mllib.linalg as mllib_lalg\n",
    "import pyspark.mllib.classification as mllib_class\n",
    "import pyspark.mllib.tree as mllib_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(PassengerId=u'1', Survived=u'0', Pclass=u'3', Name=u'Braund, Mr. Owen Harris', Sex=u'male', Age=u'22', SibSp=u'1', Parch=u'0', Ticket=u'A/5 21171', Fare=u'7.25', Cabin=None, Embarked=u'S')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (sqlContext.read.format(\"csv\").options(header=\"true\")\n",
    "    .load(\"./Data/train.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, PassengerId: string, Survived: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Cabin: string, Embarked: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DisplayColumnNames(dtf):\n",
    "    for i in dtf:\n",
    "        print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.drop('Name').drop('SibSp').drop('Ticket').drop('PassengerId').drop('Fare').drop('Embarked').drop('Parch').drop('Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<Survived>\n",
      "Column<Pclass>\n",
      "Column<Sex>\n",
      "Column<Age>\n"
     ]
    }
   ],
   "source": [
    "DisplayColumnNames(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting dataframe to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd=df.rdd.map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'0', u'3', u'male', u'22'],\n",
       " [u'1', u'1', u'female', u'38'],\n",
       " [u'1', u'3', u'female', u'26'],\n",
       " [u'1', u'1', u'female', u'35'],\n",
       " [u'0', u'3', u'male', u'35'],\n",
       " [u'0', u'3', u'male', None],\n",
       " [u'0', u'1', u'male', u'54'],\n",
       " [u'0', u'3', u'male', u'2'],\n",
       " [u'1', u'3', u'female', u'27'],\n",
       " [u'1', u'2', u'female', u'14']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Labelled Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Myfunct(line):\n",
    "    temp=[]\n",
    "    for i in line:\n",
    "        #print i\n",
    "        temp.append(i)\n",
    "    TargetVariable,Pclass,Sex,Age=temp\n",
    "    features = [(0 if Age==None else Age) ,(1 if Sex == 'female' else 0),(Pclass)]\n",
    "    return LabeledPoint(1 if TargetVariable == '1' else 0, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_points_rdd = rdd.map(Myfunct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [22.0,0.0,3.0]),\n",
       " LabeledPoint(1.0, [38.0,1.0,1.0]),\n",
       " LabeledPoint(1.0, [26.0,1.0,3.0]),\n",
       " LabeledPoint(1.0, [35.0,1.0,1.0]),\n",
       " LabeledPoint(0.0, [35.0,0.0,3.0]),\n",
       " LabeledPoint(0.0, [0.0,0.0,3.0]),\n",
       " LabeledPoint(0.0, [54.0,0.0,1.0]),\n",
       " LabeledPoint(0.0, [2.0,0.0,3.0]),\n",
       " LabeledPoint(1.0, [27.0,1.0,3.0]),\n",
       " LabeledPoint(1.0, [14.0,1.0,2.0])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_points_rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = labeled_points_rdd.randomSplit([0.7, 0.3], seed = 13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.694980695\n"
     ]
    }
   ],
   "source": [
    "# parameters:\n",
    "lamda = 1.0\n",
    "\n",
    "# initialize classifier:\n",
    "nbay = mllib_class.NaiveBayes.train(train, lamda)\n",
    "\n",
    "# Make prediction and test accuracy.\n",
    "predictionAndLabel = test.map(lambda p : (nbay.predict(p.features), p.label))\n",
    "testErr = predictionAndLabel.filter(lambda (v, p): v != p).count() / float(test.count())\n",
    "accuracy = 100.0 * predictionAndLabel.filter(lambda (x, v): x == v).count() / test.count()\n",
    "print accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
